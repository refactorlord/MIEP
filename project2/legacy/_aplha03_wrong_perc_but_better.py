import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# === ÐŸÐÐ ÐÐœÐ•Ð¢Ð Ð« ===
NUM_SIMULATIONS = 50     # ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ð¹ Ð´Ð»Ñ Ð¿Ð¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ ÐºÐ¾Ñ€Ð¸Ð´Ð¾Ñ€Ð¾Ð²
NOISE_LEVELS = [10]       # ÑƒÑ€Ð¾Ð²Ð½Ð¸ ÑˆÑƒÐ¼Ð° (%) - Ð¼Ð¾Ð¶Ð½Ð¾ Ñ€Ð°ÑÑˆÐ¸Ñ€Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸
CSV_FILENAME = "data.csv"
RESULTS_DIR = "results"

# === Ð’Ð¡ÐŸÐžÐœÐžÐ“ÐÐ¢Ð•Ð›Ð¬ÐÐ«Ð• Ð¤Ð£ÐÐšÐ¦Ð˜Ð˜ ===

def load_data(filename):
    """
    Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· CSV.
    ÐŸÐµÑ€Ð²Ñ‹Ð¹ ÑÑ‚Ð¾Ð»Ð±ÐµÑ† â€” Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ‚Ð¾Ñ‡ÐºÐ¸, Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ â€” ÑÐ¸Ð³Ð½Ð°Ð»Ñ‹.
    """
    data = pd.read_csv(filename, header=None)
    time_points = data.iloc[:, 0].values
    signals = [data.iloc[:, i].values for i in range(1, data.shape[1])]
    return time_points, signals


def add_white_noise(signal, noise_level=0.1):
    """
    Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð±ÐµÐ»Ñ‹Ð¹ ÑˆÑƒÐ¼ Ðº ÑÐ¸Ð³Ð½Ð°Ð»Ñƒ.
    noise_level: Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚ Ð¾Ñ‚ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¸Ñ ÑÐ¸Ð³Ð½Ð°Ð»Ð°
    """
    signal_std = np.std(signal)
    noise = np.random.normal(0, noise_level * signal_std, size=len(signal))
    return signal + noise


def build_corridors(simulations):
    """
    Ð¡Ñ‚Ñ€Ð¾Ð¸Ñ‚ ÑÐ¸Ð³Ð¼Ð°-ÐºÐ¾Ñ€Ð¸Ð´Ð¾Ñ€Ñ‹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¼Ð°ÑÑÐ¸Ð²Ð° ÑÐ¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ð¹.
    """
    simulations_array = np.array(simulations)
    mean_signal = np.mean(simulations_array, axis=0)
    std_signal = np.std(simulations_array, axis=0)

    one_sigma_upper = mean_signal + std_signal
    one_sigma_lower = mean_signal - std_signal
    two_sigma_upper = mean_signal + 2 * std_signal
    two_sigma_lower = mean_signal - 2 * std_signal
    three_sigma_upper = mean_signal + 3 * std_signal
    three_sigma_lower = mean_signal - 3 * std_signal

    return {
        "mean": mean_signal,
        "std": std_signal,
        "one_sigma_upper": one_sigma_upper,
        "one_sigma_lower": one_sigma_lower,
        "two_sigma_upper": two_sigma_upper,
        "two_sigma_lower": two_sigma_lower,
        "three_sigma_upper": three_sigma_upper,
        "three_sigma_lower": three_sigma_lower
    }


def validate(signal, corridor_data):
    """
    ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚, ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ‚Ð¾Ñ‡ÐµÐº Ð¿Ð¾Ð¿Ð°Ð´Ð°ÐµÑ‚ Ð² ÑÐ¸Ð³Ð¼Ð°-ÐºÐ¾Ñ€Ð¸Ð´Ð¾Ñ€Ñ‹
    """
    length = min(len(signal), len(corridor_data["mean"]))

    in_1sigma = ((signal > corridor_data["one_sigma_lower"][:length]) &
                 (signal < corridor_data["one_sigma_upper"][:length])).sum() / length * 100
    in_2sigma = ((signal > corridor_data["two_sigma_lower"][:length]) &
                 (signal < corridor_data["two_sigma_upper"][:length])).sum() / length * 100
    in_3sigma = ((signal > corridor_data["three_sigma_lower"][:length]) &
                 (signal < corridor_data["three_sigma_upper"][:length])).sum() / length * 100

    return {
        "avg_1sigma": round(in_1sigma, 2),
        "avg_2sigma": round(in_2sigma, 2),
        "avg_3sigma": round(in_3sigma, 2)
    }


def plot_validation(time_points, test_signal, corridor_data, filename):
    """
    Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð³Ñ€Ð°Ñ„Ð¸Ðº Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ ÑÐ¸Ð³Ð½Ð°Ð»Ð° Ñ ÐºÐ¾Ñ€Ð¸Ð´Ð¾Ñ€Ð°Ð¼Ð¸
    """
    plt.figure(figsize=(12, 6))
    plt.plot(time_points, test_signal, label='Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ ÑÐ¸Ð³Ð½Ð°Ð»')
    plt.plot(time_points, corridor_data["mean"], '--', color='red', label='Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ')
    plt.fill_between(time_points, corridor_data["one_sigma_lower"], corridor_data["one_sigma_upper"],
                     color='green', alpha=0.2, label='Â±1Ïƒ')
    plt.fill_between(time_points, corridor_data["two_sigma_lower"], corridor_data["two_sigma_upper"],
                     color='orange', alpha=0.2, label='Â±2Ïƒ')
    plt.fill_between(time_points, corridor_data["three_sigma_lower"], corridor_data["three_sigma_upper"],
                     color='yellow', alpha=0.2, label='Â±3Ïƒ')

    val_result = validate(test_signal, corridor_data)
    text = "\n".join([
        f"Ð’ 1Ïƒ: {val_result['avg_1sigma']}%",
        f"Ð’ 2Ïƒ: {val_result['avg_2sigma']}%",
        f"Ð’ 3Ïƒ: {val_result['avg_3sigma']}%"
    ])

    plt.text(0.5, 0.95, text, ha='center', va='top', transform=plt.gca().transAxes, fontsize=10)
    plt.title('Ð¡Ð¸Ð³Ð½Ð°Ð» Ð¸ ÑÐ¸Ð³Ð¼Ð°-ÐºÐ¾Ñ€Ð¸Ð´Ð¾Ñ€Ñ‹')
    plt.xlabel("Ð’Ñ€ÐµÐ¼Ñ (Ñ)")
    plt.ylabel("ÐžÑ‚ÐºÐ»Ð¸Ðº")
    plt.grid(True)
    plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.15), ncol=4)
    plt.tight_layout()
    plt.savefig(filename)
    plt.close()


def generate_summary_table(results, filename="results/cross_validation_summary.csv"):
    """
    Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ ÑÐ²Ð¾Ð´Ð½ÑƒÑŽ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ ÐµÑ‘ Ð² CSV
    """
    df = pd.DataFrame(results)
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    df.to_csv(filename, index=False, encoding="utf-8-sig")
    print(f"âœ… Ð¡Ð²Ð¾Ð´Ð½Ð°Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° Ð² {filename}")
    return df


# === ÐžÐ¡ÐÐžÐ’ÐÐžÐ™ Ð¦Ð˜ÐšÐ› ===
if __name__ == "__main__":
    os.makedirs(RESULTS_DIR, exist_ok=True)
    os.makedirs(os.path.join(RESULTS_DIR, "corridors"), exist_ok=True)
    os.makedirs(os.path.join(RESULTS_DIR, "validation"), exist_ok=True)

    # --- Ð¨ÐÐ“ 1: Ð§Ñ‚ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… ---
    time_points, signals = load_data(CSV_FILENAME)
    print(f"âœ… ÐŸÑ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ð½Ð¾ {len(signals)} ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²")

    # --- Ð¨ÐÐ“ 2: ÐŸÐ¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ ÐºÐ¾Ñ€Ð¸Ð´Ð¾Ñ€Ð¾Ð² Ð´Ð»Ñ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ ÑÐ¸Ð³Ð½Ð°Ð»Ð° ---
    first_signal = signals[0]
    print("\nðŸ§ª ÐŸÐ¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ ÑÐ¸Ð³Ð¼Ð°-ÐºÐ¾Ñ€Ð¸Ð´Ð¾Ñ€Ð¾Ð²: ÑÐ¸Ð³Ð½Ð°Ð» 1")

    all_simulations = []
    for _ in range(NUM_SIMULATIONS):
        noisy = add_white_noise(first_signal, NOISE_LEVELS[0] / 100)
        all_simulations.append(noisy)

    corridor_data = build_corridors(all_simulations)
    corridor_data["time"] = time_points
    corridor_data["system_name"] = "Signal_1"
    corridor_data["noise_level"] = NOISE_LEVELS[0]

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð³Ñ€Ð°Ñ„Ð¸Ðº ÐºÐ¾Ñ€Ð¸Ð´Ð¾Ñ€Ð¾Ð²
    plt.figure(figsize=(12, 6))
    plt.plot(time_points, corridor_data["mean"], '--', color='red', label='Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ')
    plt.fill_between(time_points, corridor_data["one_sigma_lower"], corridor_data["one_sigma_upper"],
                     color='green', alpha=0.2, label='Â±1Ïƒ')
    plt.fill_between(time_points, corridor_data["two_sigma_lower"], corridor_data["two_sigma_upper"],
                     color='orange', alpha=0.2, label='Â±2Ïƒ')
    plt.fill_between(time_points, corridor_data["three_sigma_lower"], corridor_data["three_sigma_upper"],
                     color='yellow', alpha=0.2, label='Â±3Ïƒ')
    plt.title('Ð¡Ð¸Ð³Ð¼Ð°-ÐºÐ¾Ñ€Ð¸Ð´Ð¾Ñ€Ñ‹ (Signal_1)')
    plt.xlabel('Ð’Ñ€ÐµÐ¼Ñ (Ñ)')
    plt.ylabel('ÐžÑ‚ÐºÐ»Ð¸Ðº')
    plt.grid(True)
    plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.15), ncol=4)
    plt.tight_layout()
    plt.savefig(os.path.join(RESULTS_DIR, "corridors", "sigma_corridors_Signal_1.png"))
    plt.close()

    # ... (Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹ ÐºÐ¾Ð´ Ð¾ÑÑ‚Ð°ÐµÑ‚ÑÑ Ð±ÐµÐ· Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹ Ð´Ð¾ Ñ‡Ð°ÑÑ‚Ð¸ ÐºÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸)

    # --- Ð¨ÐÐ“ 3: Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ ÑÐ¸Ð³Ð½Ð°Ð»Ð° Ð½Ð° ÑÐ°Ð¼Ð¾Ð¼ ÑÐµÐ±Ðµ ---
    print("\nðŸ” Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ ÑÐ¸Ð³Ð½Ð°Ð»Ð° Ð½Ð° ÑÐ°Ð¼Ð¾Ð¼ ÑÐµÐ±Ðµ:")
    self_validation = validate(first_signal, corridor_data)
    print(self_validation)
    
    # Ð¡Ñ‚Ñ€Ð¾Ð¸Ð¼ Ð³Ñ€Ð°Ñ„Ð¸Ðº Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ ÑÐ¸Ð³Ð½Ð°Ð»Ð° Ð½Ð° ÑÐ°Ð¼Ð¾Ð¼ ÑÐµÐ±Ðµ
    plot_validation(
        time_points,
        first_signal,
        corridor_data,
        os.path.join(RESULTS_DIR, "validation", "validation.png")
    )

    # --- Ð¨ÐÐ“ 4: ÐšÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ Ð²ÑÐµÑ… Ð´Ñ€ÑƒÐ³Ð¸Ñ… ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð² ---
    other_signals = signals[1:]
    print(f"\nðŸ” ÐšÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ: {len(other_signals)} ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²")

    cv_results = []

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ ÑÐ¸Ð³Ð½Ð°Ð»Ð° Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ
    cv_results.append({
        'Ñ‚Ð¸Ð¿_Ð·Ð²ÐµÐ½Ð°': 'signal_1',
        'Ð¼Ð¸Ð½_1Ïƒ': self_validation['avg_1sigma'],
        'ÑÑ€_1Ïƒ': self_validation['avg_1sigma'],
        'Ð¼Ð°ÐºÑ_1Ïƒ': self_validation['avg_1sigma'],
        'Ð¼Ð¸Ð½_2Ïƒ': self_validation['avg_2sigma'],
        'ÑÑ€_2Ïƒ': self_validation['avg_2sigma'],
        'Ð¼Ð°ÐºÑ_2Ïƒ': self_validation['avg_2sigma'],
        'Ð¼Ð¸Ð½_3Ïƒ': self_validation['avg_3sigma'],
        'ÑÑ€_3Ïƒ': self_validation['avg_3sigma'],
        'Ð¼Ð°ÐºÑ_3Ïƒ': self_validation['avg_3sigma']
    })

    for idx, signal in enumerate(other_signals):
        print(f"ðŸ”¬ ÐšÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ: ÑÐ¸Ð³Ð½Ð°Ð» {idx + 2}")

        percent_1sigma_list = []
        percent_2sigma_list = []
        percent_3sigma_list = []

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ 50 Ð²ÐµÑ€ÑÐ¸Ð¹ ÑÐ¸Ð³Ð½Ð°Ð»Ð° Ñ ÑˆÑƒÐ¼Ð¾Ð¼
        for _ in range(NUM_SIMULATIONS):
            noisy_signal = add_white_noise(signal, NOISE_LEVELS[0] / 100)
            val_result = validate(noisy_signal, corridor_data)
            percent_1sigma_list.append(val_result["avg_1sigma"])
            percent_2sigma_list.append(val_result["avg_2sigma"])
            percent_3sigma_list.append(val_result["avg_3sigma"])

        # Ð Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸
        stats = {
            '1sigma': {
                'min': np.min(percent_1sigma_list),
                'avg': np.mean(percent_1sigma_list),
                'max': np.max(percent_1sigma_list)
            },
            '2sigma': {
                'min': np.min(percent_2sigma_list),
                'avg': np.mean(percent_2sigma_list),
                'max': np.max(percent_2sigma_list)
            },
            '3sigma': {
                'min': np.min(percent_3sigma_list),
                'avg': np.mean(percent_3sigma_list),
                'max': np.max(percent_3sigma_list)
            }
        }

        cv_results.append({
            'Ñ‚Ð¸Ð¿_Ð·Ð²ÐµÐ½Ð°': f'signal_{idx + 2}',
            'Ð¼Ð¸Ð½_1Ïƒ': round(stats['1sigma']['min'], 2),
            'ÑÑ€_1Ïƒ': round(stats['1sigma']['avg'], 2),
            'Ð¼Ð°ÐºÑ_1Ïƒ': round(stats['1sigma']['max'], 2),
            'Ð¼Ð¸Ð½_2Ïƒ': round(stats['2sigma']['min'], 2),
            'ÑÑ€_2Ïƒ': round(stats['2sigma']['avg'], 2),
            'Ð¼Ð°ÐºÑ_2Ïƒ': round(stats['2sigma']['max'], 2),
            'Ð¼Ð¸Ð½_3Ïƒ': round(stats['3sigma']['min'], 2),
            'ÑÑ€_3Ïƒ': round(stats['3sigma']['avg'], 2),
            'Ð¼Ð°ÐºÑ_3Ïƒ': round(stats['3sigma']['max'], 2)
        })

        # Ð¡Ñ‚Ñ€Ð¾Ð¸Ð¼ Ð³Ñ€Ð°Ñ„Ð¸Ðº ÐºÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸
        plot_validation(
            time_points,
            signal,
            corridor_data,
            os.path.join(RESULTS_DIR, "validation", f"cross_validation_signal_{idx + 2}.png")
        )

    # --- Ð¨ÐÐ“ 5: Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ ÑÐ²Ð¾Ð´Ð½Ð¾Ð¹ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ ---
    # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð¸ ÑÐ¸Ð³Ð½Ð°Ð»Ð°
    cv_results_sorted = sorted(cv_results, key=lambda x: int(x['Ñ‚Ð¸Ð¿_Ð·Ð²ÐµÐ½Ð°'].split('_')[1]))
    summary_df = generate_summary_table(cv_results_sorted, os.path.join(RESULTS_DIR, "cross_validation_summary.csv"))
    
    print("\nðŸ“Š Ð¡Ð²Ð¾Ð´Ð½Ð°Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²:")
    print(summary_df.to_string(index=False))